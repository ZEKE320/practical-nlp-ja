{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_Bag_of_N_Grams.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_hosDAcZwSq"
      },
      "source": [
        "## Bag of N-Grams\n",
        "\n",
        "one-hotエンコーディングやBoW、TF-IDFは、単語を独立した単位として扱います。そのため、フレーズや単語の順序は考慮しません。Bag of Ngrams（BoN）アプローチはこの問題の解決を試みます。このアプローチでは、テキストをn個の連続する単語やトークンからなるチャンクに分割します。これにより、以前のアプローチでは実現できなかった文脈の考慮が可能になります。先の例で使用したのと同じコーパスを使って、このアプローチがどのように機能するか見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wE4F2qCx7NvL",
        "outputId": "90d66d41-35b6-4493-be94-2b627addabb7"
      },
      "source": [
        "documents = [\n",
        "    \"Dog bites man.\",\n",
        "    \"Man bites dog.\",\n",
        "    \"Dog eats meat.\",\n",
        "    \"Man eats food.\"\n",
        "]\n",
        "processed_docs = [doc.lower().replace(\".\", \"\") for doc in documents]\n",
        "processed_docs"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khNajktSVfnS"
      },
      "source": [
        "先の例では、CountVectorizerをBoWを作るために利用しましたが、ngram_range引数を設定すると、Bag of N-gramsの表現を得るのに使えます。以下のコードはその方法を示しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7-VReVY5jZr",
        "outputId": "b654cd30-9926-4c06-dba6-a86202f26733"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# CountVectorizerを用いてnグラム（n=1, 2, 3）のベクトル化\n",
        "count_vect = CountVectorizer(ngram_range=(1,3))\n",
        "\n",
        "# BoN表現の構築\n",
        "bow_rep = count_vect.fit_transform(processed_docs)\n",
        "\n",
        "# ボキャブラリの確認\n",
        "print(\"Our vocabulary: \", count_vect.vocabulary_)\n",
        "\n",
        "# 最初の2つの文書に対するBoNの確認\n",
        "print(\"BoW representation for 'dog bites man': \", bow_rep[0].toarray())\n",
        "print(\"BoW representation for 'man bites dog': \", bow_rep[1].toarray())\n",
        "\n",
        "# 新しいテキストに対するBoNの確認\n",
        "temp = count_vect.transform([\"dog and dog are friends\"])\n",
        "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our vocabulary:  {'dog': 3, 'bites': 0, 'man': 12, 'dog bites': 4, 'bites man': 2, 'dog bites man': 5, 'man bites': 13, 'bites dog': 1, 'man bites dog': 14, 'eats': 8, 'meat': 17, 'dog eats': 6, 'eats meat': 10, 'dog eats meat': 7, 'food': 11, 'man eats': 15, 'eats food': 9, 'man eats food': 16}\n",
            "BoW representation for 'dog bites man':  [[1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0]]\n",
            "BoW representation for 'man bites dog':  [[1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0]]\n",
            "Bow representation for 'dog and dog are friends': [[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNG5mUeWVohV"
      },
      "source": [
        "特徴数が増えて、その結果として特徴ベクトルのサイズが大きくなっていることに注意してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0hHQgJeFXv3"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    }
  ]
}