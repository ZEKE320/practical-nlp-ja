{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXRg7SWwkv-0"
      },
      "source": [
        "# 生体医療分野の固有表現認識におけるBERTとPubMedBERTの性能を比較する\n",
        "\n",
        "注：このノートブックは日本語版のおまけです。GPUを使うことを推奨します。\n",
        "\n",
        "## 準備\n",
        "\n",
        "### インストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIRgwnlmkd_S",
        "outputId": "461794e6-4e7c-409c-c645-8f17a8092f0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 6.0 MB 4.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 451 kB 45.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 628 kB 49.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 48.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 36.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 120 kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 35.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 41.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 48.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 36.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 37.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq spacy[transformers]==3.2.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTfl7ZZ5k_nX"
      },
      "source": [
        "### データセットのダウンロード\n",
        "\n",
        "今回は、BC5CDRと呼ばれるデータセットを使って、生体医療分野の固有表現認識をします。認識する固有表現タイプはChemicalとDiseaseの2種類です。\n",
        "\n",
        "https://github.com/cambridgeltl/MTL-Bioinformatics-2016/tree/master/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EivKOaPaktAt",
        "outputId": "a11b8cfe-586e-4eac-e8f6-9e94f5092914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-03 00:56:24--  https://raw.githubusercontent.com/cambridgeltl/MTL-Bioinformatics-2016/master/data/BC5CDR-IOB/train.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1039940 (1016K) [text/plain]\n",
            "Saving to: ‘train.tsv’\n",
            "\n",
            "train.tsv           100%[===================>]   1016K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-02-03 00:56:25 (22.0 MB/s) - ‘train.tsv’ saved [1039940/1039940]\n",
            "\n",
            "--2022-02-03 00:56:25--  https://raw.githubusercontent.com/cambridgeltl/MTL-Bioinformatics-2016/master/data/BC5CDR-IOB/devel.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1031781 (1008K) [text/plain]\n",
            "Saving to: ‘devel.tsv’\n",
            "\n",
            "devel.tsv           100%[===================>]   1008K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-02-03 00:56:25 (21.7 MB/s) - ‘devel.tsv’ saved [1031781/1031781]\n",
            "\n",
            "--2022-02-03 00:56:25--  https://raw.githubusercontent.com/cambridgeltl/MTL-Bioinformatics-2016/master/data/BC5CDR-IOB/test.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1080717 (1.0M) [text/plain]\n",
            "Saving to: ‘test.tsv’\n",
            "\n",
            "test.tsv            100%[===================>]   1.03M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-02-03 00:56:25 (20.6 MB/s) - ‘test.tsv’ saved [1080717/1080717]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/cambridgeltl/MTL-Bioinformatics-2016/master/data/BC5CDR-IOB/train.tsv\n",
        "!wget https://raw.githubusercontent.com/cambridgeltl/MTL-Bioinformatics-2016/master/data/BC5CDR-IOB/devel.tsv\n",
        "!wget https://raw.githubusercontent.com/cambridgeltl/MTL-Bioinformatics-2016/master/data/BC5CDR-IOB/test.tsv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head train.tsv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA-ab7sbi0wj",
        "outputId": "31af4ce8-4606-4350-9f47-54b9b63a9434"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selegiline\tB-Chemical\n",
            "-\tO\n",
            "induced\tO\n",
            "postural\tB-Disease\n",
            "hypotension\tI-Disease\n",
            "in\tO\n",
            "Parkinson\tB-Disease\n",
            "'\tI-Disease\n",
            "s\tI-Disease\n",
            "disease\tI-Disease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCkCi0eZlHTG"
      },
      "source": [
        "### データセットの変換\n",
        "\n",
        "ダウンロードしたデータセットを`spacy convert`コマンドを使ってspaCy形式に変換します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5G1AAAnlBjh",
        "outputId": "61e40a93-ec52-4648-a822-da0676c2e2f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (456 documents): corpus/train.spacy\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (480 documents): corpus/test.spacy\u001b[0m\n",
            "\u001b[38;5;4mℹ Auto-detected token-per-line NER format\u001b[0m\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (459 documents): corpus/devel.spacy\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!mkdir corpus\n",
        "!python3 -m spacy convert \"train.tsv\" corpus -c ner -n 10\n",
        "!python3 -m spacy convert \"test.tsv\" corpus -c ner -n 10\n",
        "!python3 -m spacy convert \"devel.tsv\" corpus -c ner -n 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFouThePlKqu"
      },
      "source": [
        "### 設定ファイルの作成\n",
        "\n",
        "設定ファイルを作成します。`components.transformer.model`セクションの`name`に`bert-base-uncased`を指定しています。\n",
        "\n",
        "https://spacy.io/usage/training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9CsqqCElIo-",
        "outputId": "6b1f96c0-7b59-4f9a-d5b3-e948f6292410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing base_config.cfg\n"
          ]
        }
      ],
      "source": [
        "%%writefile base_config.cfg\n",
        "# This is an auto-generated partial config. To use it with 'spacy train'\n",
        "# you can run spacy init fill-config to auto-fill all default settings:\n",
        "# python -m spacy init fill-config ./base_config.cfg ./config.cfg\n",
        "[paths]\n",
        "train = null\n",
        "dev = null\n",
        "\n",
        "[system]\n",
        "gpu_allocator = \"pytorch\"\n",
        "\n",
        "[nlp]\n",
        "lang = \"en\"\n",
        "pipeline = [\"transformer\",\"ner\"]\n",
        "batch_size = 128\n",
        "\n",
        "[components]\n",
        "\n",
        "[components.transformer]\n",
        "factory = \"transformer\"\n",
        "\n",
        "[components.transformer.model]\n",
        "@architectures = \"spacy-transformers.TransformerModel.v3\"\n",
        "name = \"bert-base-uncased\"\n",
        "tokenizer_config = {\"use_fast\": true}\n",
        "\n",
        "[components.transformer.model.get_spans]\n",
        "@span_getters = \"spacy-transformers.strided_spans.v1\"\n",
        "window = 128\n",
        "stride = 96\n",
        "\n",
        "[components.ner]\n",
        "factory = \"ner\"\n",
        "\n",
        "[components.ner.model]\n",
        "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
        "state_type = \"ner\"\n",
        "extra_state_tokens = false\n",
        "hidden_width = 64\n",
        "maxout_pieces = 2\n",
        "use_upper = false\n",
        "nO = null\n",
        "\n",
        "[components.ner.model.tok2vec]\n",
        "@architectures = \"spacy-transformers.TransformerListener.v1\"\n",
        "grad_factor = 1.0\n",
        "\n",
        "[components.ner.model.tok2vec.pooling]\n",
        "@layers = \"reduce_mean.v1\"\n",
        "\n",
        "[corpora]\n",
        "\n",
        "[corpora.train]\n",
        "@readers = \"spacy.Corpus.v1\"\n",
        "path = ${paths.train}\n",
        "max_length = 0\n",
        "\n",
        "[corpora.dev]\n",
        "@readers = \"spacy.Corpus.v1\"\n",
        "path = ${paths.dev}\n",
        "max_length = 0\n",
        "\n",
        "[training]\n",
        "accumulate_gradient = 3\n",
        "dev_corpus = \"corpora.dev\"\n",
        "train_corpus = \"corpora.train\"\n",
        "\n",
        "[training.optimizer]\n",
        "@optimizers = \"Adam.v1\"\n",
        "\n",
        "[training.optimizer.learn_rate]\n",
        "@schedules = \"warmup_linear.v1\"\n",
        "warmup_steps = 250\n",
        "total_steps = 20000\n",
        "initial_rate = 5e-5\n",
        "\n",
        "[training.batcher]\n",
        "@batchers = \"spacy.batch_by_padded.v1\"\n",
        "discard_oversize = true\n",
        "size = 2000\n",
        "buffer = 256\n",
        "\n",
        "[initialize]\n",
        "vectors = ${paths.vectors}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuOCplJplQ2G",
        "outputId": "814b525a-a743-4e05-db79-ebc16d58697b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agArKsuZlXkn"
      },
      "source": [
        "## BERT\n",
        "### モデルの学習\n",
        "\n",
        "まずはBERTを使ってモデルを学習してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG1BOiW1lVLx",
        "outputId": "e2922ce8-0e63-4ff4-c033-edbc6c20ddb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: model\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: model\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-02-02 22:17:06,034] [INFO] Set up nlp object from config\n",
            "[2022-02-02 22:17:06,047] [INFO] Pipeline: ['transformer', 'ner']\n",
            "[2022-02-02 22:17:06,052] [INFO] Created vocabulary\n",
            "[2022-02-02 22:17:06,054] [INFO] Finished initializing nlp object\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 26.1kB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 528kB/s]\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 706kB/s]\n",
            "Downloading: 100% 455k/455k [00:00<00:00, 1.14MB/s]\n",
            "Downloading: 100% 420M/420M [00:10<00:00, 43.8MB/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2022-02-02 22:18:37,934] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0         446.97    396.84    0.53    0.33    1.33    0.01\n",
            "  3     200       45440.70  55667.02   82.69   82.85   82.53    0.83\n",
            "  6     400        2264.60   4004.20   86.07   83.80   88.46    0.86\n",
            "  9     600         807.18   1237.35   87.67   88.31   87.04    0.88\n",
            " 12     800         447.90    725.25   87.60   87.88   87.32    0.88\n",
            " 15    1000         306.13    515.55   87.16   85.76   88.62    0.87\n",
            " 18    1200         193.93    293.55   87.16   86.17   88.17    0.87\n",
            " 21    1400         197.27    237.68   87.59   87.24   87.94    0.88\n",
            " 24    1600         150.69    213.22   85.87   82.88   89.08    0.86\n",
            " 27    1800         133.39    174.88   87.29   88.29   86.31    0.87\n",
            " 30    2000         115.73    160.17   87.75   87.36   88.14    0.88\n",
            " 33    2200          64.80     75.48   87.56   87.64   87.49    0.88\n",
            " 36    2400          99.68    129.25   87.24   87.48   87.00    0.87\n",
            " 39    2600          51.74     70.29   87.61   87.61   87.62    0.88\n",
            " 42    2800          41.39     54.25   87.41   86.62   88.22    0.87\n",
            " 45    3000          40.00     61.59   87.51   87.24   87.79    0.88\n",
            " 49    3200          29.00     32.84   87.12   86.71   87.53    0.87\n",
            " 52    3400          62.67     64.35   87.67   86.34   89.04    0.88\n",
            " 55    3600          22.06     34.50   87.61   86.50   88.75    0.88\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "model/model-last\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy train config.cfg \\\n",
        "         --output=./model \\\n",
        "         --paths.train corpus/train.spacy \\\n",
        "         --paths.dev corpus/devel.spacy \\\n",
        "         --training.patience 1000 \\\n",
        "         --gpu-id 0 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTU5qq3Cldqr"
      },
      "source": [
        "### モデルの評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNBqSZjOlZUA",
        "outputId": "4b3a96b6-e270-4b13-a20d-24695a6b0a1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     -    \n",
            "NER P   85.24\n",
            "NER R   87.15\n",
            "NER F   86.19\n",
            "SPEED   3530 \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "               P       R       F\n",
            "Disease    81.13   83.70   82.40\n",
            "Chemical   88.67   89.99   89.33\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy evaluate model/model-best corpus/test.spacy --gpu-id 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PubMedBERT\n",
        "\n",
        "### モデルの学習\n",
        "\n",
        "では次に、PubMedBERTを使って学習してみましょう。設定ファイルはそのままで、使うモデル名をオプションで指定します。\n",
        "\n",
        "https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext"
      ],
      "metadata": {
        "id": "56rRhqBVf-z_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train config.cfg \\\n",
        "        --output=./pubmed \\\n",
        "        --paths.train corpus/train.spacy \\\n",
        "        --paths.dev corpus/devel.spacy \\\n",
        "        --gpu-id 0 \\\n",
        "        --training.patience 1000 \\\n",
        "        --components.transformer.model.name microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbrUk533gBBl",
        "outputId": "da842166-cbb4-4240-a0a2-ffcd966bdc22"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: pubmed\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-02-03 01:13:00,639] [INFO] Set up nlp object from config\n",
            "[2022-02-03 01:13:00,653] [INFO] Pipeline: ['transformer', 'ner']\n",
            "[2022-02-03 01:13:00,658] [INFO] Created vocabulary\n",
            "[2022-02-03 01:13:00,659] [INFO] Finished initializing nlp object\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 34.6kB/s]\n",
            "Downloading: 100% 385/385 [00:00<00:00, 401kB/s]\n",
            "Downloading: 100% 221k/221k [00:00<00:00, 2.03MB/s]\n",
            "Downloading: 100% 420M/420M [00:20<00:00, 21.4MB/s]\n",
            "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2022-02-03 01:14:36,618] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0         353.91    316.46    0.46    0.27    1.49    0.00\n",
            "  3     200       55038.06  58858.95   89.49   90.67   88.35    0.89\n",
            "  6     400        2298.66   2952.42   90.16   91.37   88.97    0.90\n",
            "  9     600         753.39    929.23   90.75   90.55   90.94    0.91\n",
            " 12     800         425.75    481.66   90.50   89.63   91.39    0.91\n",
            " 15    1000         270.42    307.08   90.60   89.92   91.29    0.91\n",
            " 18    1200         200.29    203.89   90.69   91.33   90.07    0.91\n",
            " 21    1400         150.51    162.10   90.92   91.06   90.77    0.91\n",
            " 24    1600         130.72    114.51   91.32   91.58   91.06    0.91\n",
            " 27    1800         123.42    118.64   91.23   92.53   89.97    0.91\n",
            " 30    2000          78.32     72.87   90.91   91.32   90.50    0.91\n",
            " 33    2200          61.22     50.16   91.20   90.59   91.82    0.91\n",
            " 36    2400          62.28     47.97   90.97   90.56   91.39    0.91\n",
            " 39    2600          89.87     84.70   91.19   91.03   91.34    0.91\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "pubmed/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデルの評価"
      ],
      "metadata": {
        "id": "0_LP6W12jkhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy evaluate pubmed/model-best corpus/test.spacy --gpu-id 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsJ4W8ODjmke",
        "outputId": "d4824004-35c2-4934-9772-3e54a1ea88d6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     -    \n",
            "NER P   89.91\n",
            "NER R   90.43\n",
            "NER F   90.17\n",
            "SPEED   4176 \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "               P       R       F\n",
            "Disease    85.06   87.12   86.07\n",
            "Chemical   94.04   93.15   93.59\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fh0rZlBh-HWh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "spaCy_bert_vs_pubmedbert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}