{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_BERT_Sentiment_Classification_IMDB_ktrain.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypR4NNY7oyEV"
      },
      "source": [
        "# ktrainから使うBERT\n",
        "\n",
        "ktrainはKerasのラッパーであり、ニューラルネットワークを簡単に学習できます。わずか数行のコードを書くだけでモデルを構築し、最適な学習率を推定し、テキストの読み込みや前処理を行い、モデルを学習できます。\n",
        "\n",
        "- https://github.com/amaiya/ktrain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LezMFAkaROCc"
      },
      "source": [
        "## 準備\n",
        "\n",
        "### パッケージのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58WB13Jx3rQm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b459dda-1d88-4e52-a46f-e4682124eae2"
      },
      "source": [
        "!pip3 install ktrain==0.27.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ktrain==0.27.3\n",
            "  Downloading ktrain-0.27.3.tar.gz (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 96 kB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 35.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain==0.27.3) (3.2.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from ktrain==0.27.3) (1.1.5)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/dist-packages (from ktrain==0.27.3) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ktrain==0.27.3) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain==0.27.3) (1.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ktrain==0.27.3) (21.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ktrain==0.27.3) (5.5.0)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 31.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain==0.27.3) (0.42.1)\n",
            "Collecting cchardet\n",
            "  Downloading cchardet-2.1.7-cp37-cp37m-manylinux2010_x86_64.whl (263 kB)\n",
            "\u001b[K     |████████████████████████████████| 263 kB 43.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from ktrain==0.27.3) (3.0.4)\n",
            "Collecting syntok\n",
            "  Downloading syntok-1.3.1.tar.gz (23 kB)\n",
            "Collecting seqeval==0.0.19\n",
            "  Downloading seqeval-0.0.19.tar.gz (30 kB)\n",
            "Collecting transformers<=4.3.3,>=4.0.0\n",
            "  Downloading transformers-4.3.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 31.1 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 35.5 MB/s \n",
            "\u001b[?25hCollecting keras_bert>=0.86.0\n",
            "  Downloading keras-bert-0.88.0.tar.gz (26 kB)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.7/dist-packages (from ktrain==0.27.3) (2.6.2)\n",
            "Collecting whoosh\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[K     |████████████████████████████████| 468 kB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain==0.27.3) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain==0.27.3) (1.19.5)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.19->ktrain==0.27.3) (2.6.0)\n",
            "Collecting keras-transformer>=0.39.0\n",
            "  Downloading keras-transformer-0.39.0.tar.gz (11 kB)\n",
            "Collecting keras-pos-embd>=0.12.0\n",
            "  Downloading keras-pos-embd-0.12.0.tar.gz (6.0 kB)\n",
            "Collecting keras-multi-head>=0.28.0\n",
            "  Downloading keras-multi-head-0.28.0.tar.gz (14 kB)\n",
            "Collecting keras-layer-normalization>=0.15.0\n",
            "  Downloading keras-layer-normalization-0.15.0.tar.gz (4.2 kB)\n",
            "Collecting keras-position-wise-feed-forward>=0.7.0\n",
            "  Downloading keras-position-wise-feed-forward-0.7.0.tar.gz (4.5 kB)\n",
            "Collecting keras-embed-sim>=0.9.0\n",
            "  Downloading keras-embed-sim-0.9.0.tar.gz (4.1 kB)\n",
            "Collecting keras-self-attention>=0.50.0\n",
            "  Downloading keras-self-attention-0.50.0.tar.gz (12 kB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain==0.27.3) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain==0.27.3) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain==0.27.3) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain==0.27.3) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0.0->ktrain==0.27.3) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->ktrain==0.27.3) (2018.9)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain==0.27.3) (4.6.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain==0.27.3) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 36.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain==0.27.3) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 34.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.3.3,>=4.0.0->ktrain==0.27.3) (4.62.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.3.3,>=4.0.0->ktrain==0.27.3) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.3.3,>=4.0.0->ktrain==0.27.3) (3.5.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain==0.27.3) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain==0.27.3) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain==0.27.3) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain==0.27.3) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain==0.27.3) (5.0.5)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain==0.27.3) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain==0.27.3) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ktrain==0.27.3) (4.4.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain==0.27.3) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->ktrain==0.27.3) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ktrain==0.27.3) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain==0.27.3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain==0.27.3) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain==0.27.3) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.3.3,>=4.0.0->ktrain==0.27.3) (7.1.2)\n",
            "Building wheels for collected packages: ktrain, seqeval, keras-bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, syntok\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.27.3-py3-none-any.whl size=25283131 sha256=fa918db910b5deb03c38c50d084471fb1aeda8b7a5fa19c976db817bef8d54f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/ef/e1/7da805d8a5944e8a3ac0553831d832c00b1800b848939849cb\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.19-py3-none-any.whl size=9929 sha256=3b9cc4b3bc1181000cbb32fdda05a3b2e6fabe07627d1e6f8816dd2ecfec53bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/ac/f1/4e13d7aff05c722d142b7d20a88ad63f9aab11b895411241a4\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.88.0-py3-none-any.whl size=34204 sha256=ef20e8d7245bf517cdf8b7a968ca6f855490614e4463309fe15dff17b711624a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/90/cd/c038f2366929a3a5e3414a303b673e10235e802d871d29a835\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.39.0-py3-none-any.whl size=12842 sha256=5700a2944faf71103d644383201ccc214dac7f368cbea1c187d046bdc80d6d90\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/01/e0/5a1a14bed6726f2ed73f7917d2d2c2d4081d2c88426dea07ce\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.9.0-py3-none-any.whl size=4504 sha256=d5fc12d815c826ad783aea9d16626e059e1aef28445316865e2ee79c49a94b88\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/1e/d2/9bc15513dd2f8b9de3e628b3aa9d2de49e721deef6bbd1497e\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.15.0-py3-none-any.whl size=5224 sha256=0562f5c43265522875b29314f9d07340cce62ada5c81a18a9b03c8b3e2cb02d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/4d/be/fe/55422f77ac11fe6ddcb471198038de8a26b5a4dd1557883c1e\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.28.0-py3-none-any.whl size=15559 sha256=ee7cd32c5939212850a14444b48a411a3d0e8c9373e576e03b5637f20d0f6d7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/4a/ea/9503ab5a02201dfb8635ba2cc8f30844661623c684a5b44472\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.12.0-py3-none-any.whl size=7469 sha256=2ddbb945a6953d5df8fffc055c156f809e6e23c29584a2a3630b039a3cb5d922\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/99/fd/dd98f4876c3ebbef7aab0dbfbd37bca41d7db37d3a28b2cb09\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.7.0-py3-none-any.whl size=5541 sha256=c8a81711727720107e32ce0fc9d1eb61d07b079c969e479157c15a521d48753b\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/12/02/1ad455c4f181cda1a4e60c5445855853d5c2ea91f942586a04\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.50.0-py3-none-any.whl size=19414 sha256=43bdb94f1c841ce1a0ad23d748f8e4992d52184340b4bd3700f598da42f26577\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/7a/a3/231bef5803298e7ec1815215bc0613239cb1e9c03c57b13c14\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=5bf75e59f42cf864921a55f52d3ae98dd28bbf9cf3453fb9aba757cca0173ace\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for syntok: filename=syntok-1.3.1-py3-none-any.whl size=20917 sha256=3a6bdc414cc8955fb9198cf39736d3ab3f85c065066f8f6155a2d2484e2ab63a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/c2/33/e5d7d8f2f8b0c391d76bf82b844c3151bf23a84d75d02b185f\n",
            "Successfully built ktrain seqeval keras-bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect syntok\n",
            "Installing collected packages: keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-embed-sim, tokenizers, threadpoolctl, sacremoses, keras-transformer, whoosh, transformers, syntok, seqeval, sentencepiece, scikit-learn, langdetect, keras-bert, cchardet, ktrain\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed cchardet-2.1.7 keras-bert-0.88.0 keras-embed-sim-0.9.0 keras-layer-normalization-0.15.0 keras-multi-head-0.28.0 keras-pos-embd-0.12.0 keras-position-wise-feed-forward-0.7.0 keras-self-attention-0.50.0 keras-transformer-0.39.0 ktrain-0.27.3 langdetect-1.0.9 sacremoses-0.0.45 scikit-learn-0.23.2 sentencepiece-0.1.96 seqeval-0.0.19 syntok-1.3.1 threadpoolctl-2.2.0 tokenizers-0.10.3 transformers-4.3.3 whoosh-2.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPe9aJ4ZRSWO"
      },
      "source": [
        "### インポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN6N85ah8VXf"
      },
      "source": [
        "import ktrain\n",
        "from ktrain import text"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S326wZCORYuw"
      },
      "source": [
        "### データセットのダウンロード\n",
        "\n",
        "データセットは以前にも使ったIMDB映画レビューデータセットを使います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr1YXudk8Vti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f64d8e-5de1-4fae-fc97-01b16ac56b42"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\",\n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "    extract=True,\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 6s 0us/step\n",
            "84140032/84125825 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x46reXu9Kru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d327b7e-6797-4c2a-d628-b3df443033b2"
      },
      "source": [
        "%cd /root/.keras/datasets/aclImdb\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets/aclImdb\n",
            "imdbEr.txt  imdb.vocab\tREADME\ttest  train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSOtBCMXUF5G"
      },
      "source": [
        "読み込むときのために、フォルダの構造を確認しておきましょう。\n",
        "`train`と`test`の下に`pos`と`neg`フォルダがあり、その中にプレーンテキストでレビューが格納されています。おおよそ、以下の構造になります。\n",
        "\n",
        "```bash\n",
        "├── datadir\n",
        "│   ├── train\n",
        "│   │   ├── pos       # 肯定的なレビューのテキストを含むフォルダ\n",
        "│   │   └── neg       # 否定的なレビューのテキストを含むフォルダ\n",
        "│   └── test \n",
        "│        ├── pos       # 肯定的なレビューのテキストを含むフォルダ\n",
        "│        └── neg       # 否定的なレビューのテキストを含むフォルダ\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8We3IZ4ETbtV",
        "outputId": "7bdca4e8-7268-4b8f-a889-e9b139453092"
      },
      "source": [
        "!ls -F train"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeledBow.feat  pos/\t unsupBow.feat\turls_pos.txt\n",
            "neg/\t\t unsup/  urls_neg.txt\turls_unsup.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnXQ-lcL8d6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be6fa21-f141-45f2-a120-e2c091a5dadd"
      },
      "source": [
        "# set path to dataset\n",
        "import os.path\n",
        "\n",
        "dataset = \"/root/.keras/datasets/aclImdb\"\n",
        "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
        "print(IMDB_DATADIR)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets/aclImdb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugopbOABrmne"
      },
      "source": [
        "## 前処理\n",
        "\n",
        "`texts_from_folder`関数を使うと、学習用と検証用のデータを指定したフォルダから読み込み、BERTに必要な形式へ自動的に変換してくれます。この関数は、以下のようなフォルダ構造でコーパスが格納されていることを仮定しています。\n",
        "\n",
        "```bash\n",
        "├── datadir\n",
        "│   ├── train\n",
        "│   │   ├── class0       # folder containing documents of class 0\n",
        "│   │   ├── class1       # folder containing documents of class 1\n",
        "│   │   ├── class2       # folder containing documents of class 2\n",
        "│   │   └── classN       # folder containing documents of class N\n",
        "│   └── test \n",
        "│       ├── class0       # folder containing documents of class 0\n",
        "│       ├── class1       # folder containing documents of class 1\n",
        "│       ├── class2       # folder containing documents of class 2\n",
        "│       └── classN       # folder containing documents of class N\n",
        "```\n",
        "\n",
        "各サブフォルダは、プレーンテキスト形式で文書を格納していなければなりません。今回の場合、サブフォルダ名は`pos`と`neg`なので、それを`classes`引数に指定します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jELdxonN9J8v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "6c3e74bd-687e-41d0-ff42-34ec7f8e72b3"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_folder(\n",
        "    IMDB_DATADIR,\n",
        "    maxlen=128,\n",
        "    preprocess_mode=\"bert\",\n",
        "    train_test_names=[\"train\", \"test\"],\n",
        "    classes=[\"pos\", \"neg\"],\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "detected encoding: utf-8\n",
            "preprocessing train...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0SIaqHcslLZ"
      },
      "source": [
        "## 事前学習済みBERTの読み込み\n",
        "\n",
        "まずは、`text_classifier`関数を使って、テキスト分類モデルを構築します。今回はBERTを使いたいため、関数の第一引数に`bert`と渡しています。それ以外に以下の文字列を渡せます。\n",
        "\n",
        "- fasttext: FastTextモデル\n",
        "- nbsvm: NBSVM（ナイーブベイズとSVMの組み合わせ）\n",
        "- logreg: 埋め込み層を使ったロジスティック回帰\n",
        "- bigru: 事前学習済み単語埋め込みを使った双方向GRU\n",
        "- distilbert: DistilBertモデル\n",
        "\n",
        "その後、`get_learner`関数を呼び出して、モデルを学習するための`Learner`インスタンスを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90ftQ6MgAJy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac3ff39-6d9f-4093-e9bf-2dc77e260228"
      },
      "source": [
        "model = text.text_classifier(\"bert\", (x_train, y_train), preproc=preproc)\n",
        "learner = ktrain.get_learner(\n",
        "    model, train_data=(x_train, y_train), val_data=(x_test, y_test), batch_size=16\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 128\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN6zWQgys0c_"
      },
      "source": [
        "## モデルの学習\n",
        "\n",
        "ここまで来たら、あとは`fit_onecycle`メソッドを呼び出して、モデルを学習します。\n",
        "第1引数に学習率、第２引数にエポック数を指定しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fxdw88YjAfvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2b5da9-4bb8-4f6e-80c6-6311ab3957a5"
      },
      "source": [
        "learner.fit_onecycle(2e-5, 4)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "Epoch 1/4\n",
            "1563/1563 [==============================] - 1805s 1s/step - loss: 0.3853 - accuracy: 0.8230 - val_loss: 0.2926 - val_accuracy: 0.8734\n",
            "Epoch 2/4\n",
            "1563/1563 [==============================] - 1752s 1s/step - loss: 0.2580 - accuracy: 0.8931 - val_loss: 0.2750 - val_accuracy: 0.8824\n",
            "Epoch 3/4\n",
            "1563/1563 [==============================] - 1751s 1s/step - loss: 0.1463 - accuracy: 0.9458 - val_loss: 0.3092 - val_accuracy: 0.8802\n",
            "Epoch 4/4\n",
            "1563/1563 [==============================] - 1750s 1s/step - loss: 0.0393 - accuracy: 0.9885 - val_loss: 0.4177 - val_accuracy: 0.8864\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f63b0ca9e90>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPVhsfj3TwHf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}